{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION\n",
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Data\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Load Data\n",
    "\n",
    "veriler = pd.read_csv('veriler.csv')\n",
    "veriler.dropna(inplace = True)\n",
    "\n",
    "x = veriler.iloc[:, 1:4].values      # Independent Variable\n",
    "y = veriler.iloc[:, 4].values       # Dependent Variables\n",
    "\n",
    "# Split Data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test,y_train,y_test = train_test_split(x,y,test_size=0.33, random_state=0)\n",
    "\n",
    "# Scalling Data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc=StandardScaler()\n",
    "\n",
    "X_train = sc.fit_transform(x_train)\n",
    "X_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02 - Logistic Regressing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "[[0 1]\n",
      " [7 0]]\n",
      "*********************************************\n",
      "Average success of model\n",
      "0.5625\n",
      "**********************************************\n",
      "Average standard deviation of model\n",
      "0.16002386974726268\n",
      "***********************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\90545\\anaconda3\\envs\\data science\\lib\\site-packages\\sklearn\\model_selection\\_split.py:666: UserWarning: The least populated class in y has only 4 members, which is less than n_splits=10.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best result\n",
      "0.75\n",
      "**********************************************\n",
      "The best parameter\n",
      "{'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\90545\\anaconda3\\envs\\data science\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [ nan 0.7  0.65 0.65 0.75]\n",
      "  warnings.warn(\n",
      "C:\\Users\\90545\\anaconda3\\envs\\data science\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# solver : (\"newton_cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\") default = \"lbfgs\"\n",
    "# random_state default: None\n",
    "\n",
    "logr = LogisticRegression(random_state = 1, solver=\"saga\")\n",
    "\n",
    "logr.fit(X_train,y_train)  \n",
    "y_pred = logr.predict(X_test)     \n",
    "\n",
    "# Konfusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(\"Logistic Regression\")\n",
    "print(cm)\n",
    "print(\"*********************************************\")\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "basari = cross_val_score(estimator = logr, X = X_train, y = y_train , cv = 4)\n",
    "\n",
    "print(\"Average success of model\")\n",
    "print(basari.mean())    \n",
    "print(\"**********************************************\") \n",
    "\n",
    "print(\"Average standard deviation of model\")\n",
    "print(basari.std())  \n",
    "print(\"***********************************************\")       \n",
    "\n",
    "# Optimize Parameters on model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "p = [{\"solver\" : [\"newton_cg\", \"lbfgs\", \"liblinear\", \"sag\", \"saga\"]}]\n",
    "\n",
    "gs = GridSearchCV(estimator=logr, param_grid=p, scoring=\"accuracy\", cv=10, n_jobs=-1)\n",
    "grid_search = gs.fit(x_train, y_train)\n",
    "\n",
    "eniyisonuc = grid_search.best_score_\n",
    "eniyiparametre = grid_search.best_params_\n",
    "\n",
    "print(\"The best result\")\n",
    "print(eniyisonuc)\n",
    "print(\"**********************************************\")\n",
    "\n",
    "print(\"The best parameter\")\n",
    "print(eniyiparametre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03 - K-NN\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-NN\n",
      "[[0 1]\n",
      " [6 1]]\n",
      "******************************************\n",
      "Avearge success of model\n",
      "0.7083333333333334\n",
      "******************************************\n",
      "Average standard deviation of model\n",
      "0.2975595178559521\n",
      "******************************************\n",
      "The best result\n",
      "0.7083333333333334\n",
      "*****************************************\n",
      "The best parameter\n",
      "{'metric': 'minkowski', 'n_neighbors': 5, 'weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# n_neighbors default = 5\n",
    "# weights = (\"uniform\", \"distance\") default = \"uniform\"\n",
    "# metric default = \"minkowski\"\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 5, metric='minkowski', weights=\"uniform\")\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Konfusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print(\"K-NN\")\n",
    "print(cm)\n",
    "print(\"******************************************\")\n",
    "\n",
    "# K-Fold Cross Validaiton \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "basari = cross_val_score(estimator = knn, X = X_train, y = y_train , cv = 4)\n",
    "\n",
    "print(\"Avearge success of model\")\n",
    "print(basari.mean())  \n",
    "print(\"******************************************\")\n",
    "\n",
    "print(\"Average standard deviation of model\")\n",
    "print(basari.std())\n",
    "print(\"******************************************\") \n",
    "\n",
    "# Optimize parameters on model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "p = [{\"n_neighbors\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"weights\": [\"uniform\", \"distance\"], \"metric\": [\"minkowski\"]}]\n",
    "\n",
    "gs = GridSearchCV(estimator=knn, param_grid=p, scoring=\"accuracy\", cv=4, n_jobs=-1)\n",
    "grid_search = gs.fit(x_train, y_train)\n",
    "\n",
    "eniyisonuc = grid_search.best_score_\n",
    "eniyiparametre = grid_search.best_params_\n",
    "\n",
    "print(\"The best result\")\n",
    "print(eniyisonuc)\n",
    "print(\"*****************************************\")\n",
    "\n",
    "print(\"The best parameter\")\n",
    "print(eniyiparametre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04 - SVM\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC\n",
      "[[1 0]\n",
      " [7 0]]\n",
      "****************************************************\n",
      "Average success of model\n",
      "0.5625\n",
      "****************************************************\n",
      "Average standard deviation of model\n",
      "0.16002386974726268\n",
      "****************************************************\n",
      "The best result\n",
      "0.7708333333333334\n",
      "****************************************************\n",
      "The best parameter\n",
      "{'degree': 3, 'gamma': 'auto', 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\"\"\"\n",
    "kernel: (\"rbf\", \"poly\", \"linear\", \"sigmoid\", \"precomputed\") default: \"rbf\"\n",
    "degree default: \"2\"\n",
    "gamma: (\"auto\", \"scale\") default: (\"scale\")\n",
    "\"\"\"\n",
    "               \n",
    "svc = SVC(kernel = 'poly', degree = 3, gamma=\"auto\")  \n",
    "\n",
    "svc.fit(X_train,y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print('SVC')\n",
    "print(cm)\n",
    "print(\"****************************************************\")\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "basari = cross_val_score(estimator = svc, X = X_train, y = y_train , cv = 4)\n",
    "\n",
    "print(\"Average success of model\")\n",
    "print(basari.mean())        \n",
    "print(\"****************************************************\")\n",
    "\n",
    "print(\"Average standard deviation of model\")\n",
    "print(basari.std())     \n",
    "print(\"****************************************************\")\n",
    "\n",
    "# Optimize parameters on model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "p = [{\"kernel\": [\"rbf\", \"poly\", \"linear\", \"sigmoid\"], \"degree\": [2, 3, 4, 5, 6, 7, 8, 9], \"gamma\": [\"auto\", \"scale\"]}]\n",
    "\n",
    "gs = GridSearchCV(estimator=svc, param_grid=p, scoring=\"accuracy\", cv=4, n_jobs=-1)\n",
    "grid_search = gs.fit(x_train, y_train)\n",
    "\n",
    "eniyisonuc = grid_search.best_score_\n",
    "eniyiparametre = grid_search.best_params_\n",
    "\n",
    "print(\"The best result\")\n",
    "print(eniyisonuc)\n",
    "print(\"****************************************************\")\n",
    "\n",
    "print(\"The best parameter\")\n",
    "print(eniyiparametre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05 - NAVIE BAYES\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNB\n",
      "[[0 1]\n",
      " [6 1]]\n",
      "****************************************************\n",
      "Average success of model\n",
      "0.7083333333333334\n",
      "****************************************************\n",
      "Average standard deviation of mode\n",
      "0.2975595178559521\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print('GNB')\n",
    "print(cm)\n",
    "print(\"****************************************************\")\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "basari = cross_val_score(estimator = gnb, X = X_train, y = y_train , cv = 4)\n",
    "\n",
    "print(\"Average success of model\")\n",
    "print(basari.mean()) \n",
    "print(\"****************************************************\")\n",
    "       \n",
    "print(\"Average standard deviation of mode\")\n",
    "print(basari.std())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06 - DECISION TREE\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree\n",
      "[[1 0]\n",
      " [1 6]]\n",
      "****************************************************\n",
      "Average success of model\n",
      "0.8541666666666666\n",
      "****************************************************\n",
      "Average standard deviation of model\n",
      "0.14877975892797607\n",
      "****************************************************\n",
      "The best result\n",
      "0.8541666666666666\n",
      "****************************************************\n",
      "The best parameter\n",
      "{'criterion': 'entropy', 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# criterion = (\"entropy\", \"gini\") default = \"gini\"\n",
    "# splitter = (\"best\", \"random\") default = \"best\"\n",
    "\n",
    "dtc = DecisionTreeClassifier(random_state = 1, criterion = 'entropy', splitter = \"best\")\n",
    "\n",
    "dtc.fit(X_train,y_train)\n",
    "y_pred = dtc.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "print('Decision Tree')\n",
    "print(cm)\n",
    "print(\"****************************************************\")\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "basari = cross_val_score(estimator = dtc, X = X_train, y = y_train , cv = 4)\n",
    "\n",
    "print(\"Average success of model\")\n",
    "print(basari.mean())        \n",
    "print(\"****************************************************\")\n",
    "\n",
    "print(\"Average standard deviation of model\")\n",
    "print(basari.std())\n",
    "print(\"****************************************************\")\n",
    "\n",
    "# Optimize parameters on model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "p = [{\"criterion\": [\"entropy\", \"gini\"], \"splitter\": [\"best\", \"random\"]}]\n",
    "\n",
    "gs = GridSearchCV(estimator=dtc, param_grid=p, scoring=\"accuracy\", cv=4, n_jobs=-1)\n",
    "grid_search = gs.fit(x_train, y_train)\n",
    "\n",
    "eniyisonuc = grid_search.best_score_\n",
    "eniyiparametre = grid_search.best_params_\n",
    "\n",
    "print(\"The best result\")\n",
    "print(eniyisonuc)\n",
    "print(\"****************************************************\")\n",
    "\n",
    "print(\"The best parameter\")\n",
    "print(eniyiparametre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07 - RANDOM FOREST\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "[[0 1]\n",
      " [0 7]]\n",
      "****************************************************\n",
      "Average success of model\n",
      "0.7916666666666666\n",
      "****************************************************\n",
      "Average standard deviation of model\n",
      "0.21650635094610965\n",
      "****************************************************\n",
      "The best result\n",
      "0.8333333333333334\n",
      "****************************************************\n",
      "The best parameter\n",
      "{'criterion': 'entropy', 'n_estimators': 1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# n_estimators default = 100\n",
    "# criterion = (\"entropy\", \"gini\") default = \"gini\"\n",
    "\n",
    "rfc = RandomForestClassifier(random_state = 1, n_estimators=5, criterion = 'entropy')\n",
    "\n",
    "rfc.fit(X_train,y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print('Random Forest')\n",
    "print(cm)\n",
    "print(\"****************************************************\")\n",
    "\n",
    "# K-Fold Cross Validation\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "basari = cross_val_score(estimator = rfc, X = X_train, y = y_train , cv = 4)\n",
    "\n",
    "print(\"Average success of model\")\n",
    "print(basari.mean())   \n",
    "print(\"****************************************************\")\n",
    "\n",
    "print(\"Average standard deviation of model\")\n",
    "print(basari.std())   \n",
    "print(\"****************************************************\")\n",
    "\n",
    "# Optimize parameters on model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "p = [{\"n_estimators\": [1, 5, 10, 20, 40], \"criterion\": [\"entropy\", \"gini\"]}]\n",
    "\n",
    "gs = GridSearchCV(estimator=rfc, param_grid=p, scoring=\"accuracy\", cv=4, n_jobs=-1)\n",
    "grid_search = gs.fit(x_train, y_train)\n",
    "\n",
    "eniyisonuc = grid_search.best_score_\n",
    "eniyiparametre = grid_search.best_params_\n",
    "\n",
    "print(\"The best result\")\n",
    "print(eniyisonuc)\n",
    "\n",
    "print(\"****************************************************\")\n",
    "print(\"The best parameter\")\n",
    "print(eniyiparametre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
